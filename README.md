# Semantic Segmentation with U-Net Architecture: Capacity and Ablation Analysis

This project implements and critically evaluates the **U-Net** neural network architecture for semantic image segmentation. The work was developed as part of the **Machine Learning II** course at the **University of Las Palmas de Gran Canaria (ULPGC)**. Through a series of controlled experiments, we analyze the impact of the number of channels and the importance of skip connections on model accuracy.

## üìñ Task Introduction

Semantic segmentation is the process of classifying each pixel of an image into a specific category, allowing for the detailed spatial understanding necessary to accurately delimit objects. In this project, the goal is to segment coins in synthetic images using the U-Net architecture, known for its effectiveness due to its symmetric contraction and expansion structure.

## üèóÔ∏è Detailed Model Architecture

The model is based on three fundamental components defined in the implementation:

### 1. Encoder (Contracting Path)

* **Objective:** Capture context and extract a hierarchy of high-level features while reducing spatial dimensions.
* **Mechanism:** Utilizes repeated blocks of two 3x3 convolutions, each followed by Batch Normalization and ReLU activation.
* **Downsampling:** Employs 2x2 Max Pooling layers to halve height and width after every block, while simultaneously doubling the number of filters.

### 2. Decoder (Extending Path)

* **Objective:** Reconstruct spatial resolution and map the abstract features back to the original image dimensions for pixel-wise classification.
* **Mechanism:** Begins with 2x2 Transposed Convolutions (upsampling), followed by the same double 3x3 convolutional blocks used in the encoder.
* **Classification Layer:** A final 1x1 convolution reduces the feature map to a single channel, followed by a sigmoid-like activation to produce the probability mask.

### 3. Skip Connections (Concatenation)

* **Objective:** Recover spatial "lost" information during the downsampling process.
* **Mechanism:** Directly concatenate the high-resolution feature maps from the contracting path with the upsampled feature maps in the extending path.
* **Technical Impact:** This bridge allows the network to combine precise spatial details from the encoder with semantic, contextual information from the decoder, which is crucial for sharp edge definition.

## üöÄ Phase 1: Complexity & Simplification Study (Channels)

A progressive reduction in the number of filters at each stage was performed to observe the "Pareto frontier" between model efficiency and predictive performance.

Aqu√≠ tienes la tabla corregida y optimizada para que se visualice perfectamente en cualquier visor de Markdown (como GitHub). He ajustado las columnas para que coincidan con los encabezados y he refinado el an√°lisis t√©cnico basado en los resultados de tus experimentos.

### üöÄ Phase 1: Complexity & Simplification Study (Channels)

| Configuration | Channels (Base) | Result | Technical Analysis |
| --- | --- | --- | --- |
| **Baseline** | 64 | **Excellent** | Absolute edge precision; no artifacts. |
| **Model 1/2** | 32 | **Excellent** | Performance parity; confirms over-parameterization in the baseline. |
| **Model 1/4** | 16 | **Very Good** | Minor smoothing on fine textures, but mask integrity remains high. |
| **Model 1/8** | 8 | **Degradation** | Emergence of "noise" in the background; struggle with variance. |
| **Model 1/16** | 4 | **Poor** | Blurry masks and significant loss of circular geometry. |
| **Model 1/32** | 2 | **Underfitting** | Complete failure to converge; capacity is insufficient. |

**Key Finding:** The U-Net architecture exhibits massive redundancy for simple geometric datasets. A model with only **6.25% (1/16) of the original parameters** can still produce a recognizable segmentation mask.

## üîç Phase 2: Structural Ablation Study (Skip Connections)

This phase systematically disabled the "bridges" between the encoder and decoder to quantify their impact on spatial reconstruction.

### 1. Hierarchical Degradation Analysis

* **Deep Level (Level 4) Removal:** Disabling the deepest skip connection (closest to the bottleneck) had negligible impact. At this depth, features are highly abstract, and the bottleneck (1024 channels) carries sufficient semantic information to recover these features during upsampling.
* **Intermediate Level (Levels 3 & 2) Removal:** Performance remained surprisingly stable. However, a slight increase in false positives (background noise) was observed, indicating that intermediate connections help in "filtering" irrelevant background features.
* **Shallow Level (Level 1) Influence:** This connection (linking the 512x512 encoder output to the final decoder stage) proved to be the "anchor" for geometric precision. Even with other connections disabled, this level provides the high-resolution "template" required for sharp edges.

### 2. Pure Encoder-Decoder (No Skip 4)

* **Execution:** All connections disabled, forcing all information through the bottleneck.
* **Result:** While the model still identified the coins, the masks became "globular" and lost the crisp definition of the baseline.
* **Implication:** The bottleneck is powerful enough to classify the "what," but the skip connections are essential to define the "where" with sub-pixel accuracy.

## üìà Project Conclusions

1. **Architecture vs. Brute Force:** structural design (skip connections) is more critical for segmentation quality than raw parameter count (channels). A "thin" U-Net with skips often outperforms a "thick" Encoder-Decoder without them.
2. **Resource Optimization:** For production environments involving high-contrast, low-complexity imagery, developers should prioritize smaller channel counts (Model 1/4) to save memory and inference time.
3. **The Power of the Bridge:** Skip connections effectively solve the "vanishing detail" problem in deep networks, allowing the decoder to "look back" at the original image's high-frequency details.

## üõ†Ô∏è Technologies and Tools

* **Framework:** PyTorch (v2.x) - handling the computational graph and backpropagation.
* **Optimization:** Adam Optimizer () for robust convergence.
* **Loss Function:** MSE Loss used for binary segmentation tasks on synthetic data.
* **Hardware:** NVIDIA CUDA acceleration for high-epoch training.

## üë• Authors

This project was created by [ArtHead](https://github.com/ArtHead-Devs), featuring:

* **üë®‚Äçüíª Fabio Nesta Arteaga Cabrera**: [NestX10](https://github.com/NestX10)
* **üë®‚Äçüíª Pablo Cabeza Lantigua**: [pabcablan](https://github.com/pabcablan)

## üìÑ License

This project is licensed under the GNU General Public License v3.0. See the [LICENSE](https://www.google.com/search?q=LICENSE) file for more details.